# Service Embedding Orchestrator

This orchestrator is responsible for managing the process of creating embeddings for services. It handles:
1. Identifying services that need embeddings (empty `embedding_v2` column)
2. Tokenizing service descriptions and metadata
3. Sending tokens to networked inference workers
4. Storing the resulting embeddings back in the database

## Setup

### Prerequisites
- Rust 1.60+ with Cargo
- PostgreSQL database
- Access to inference workers

### Environment Variables
Create a `.env` file with the following variables:

```
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_password
POSTGRES_DB=your_database
PORT=3001
BATCH_SIZE=10
MODEL_ID=bge-small-en-v1.5
PIPELINE_INTERVAL_SECS=60
WORKER_LOCATIONS=inference-worker-1:3000,inference-worker-2:3000
API_KEY=your_api_key
RUST_LOG=info
```

### Database Setup
Run the database migration script to set up the embedding schema and necessary functions:

```bash
psql -U postgres -d your_database -f migrations/setup.sql
```

## Running the Orchestrator

### Development Mode
```bash
cargo run
```

### Production Mode
```bash
cargo build --release
./target/release/orchestrator
```

### Docker
```bash
docker build -t service-embedding-orchestrator .
docker run -p 3001:3001 --env-file .env service-embedding-orchestrator
```

## API Endpoints

- `GET /health` - Health check endpoint
- `GET /api/status` - Get orchestrator status and stats
- `POST /api/pipeline/run` - Manually trigger pipeline run
- `POST /api/pipeline/pause` - Pause pipeline
- `POST /api/pipeline/resume` - Resume pipeline
- `GET /api/stats` - Get pipeline statistics
- `GET /api/workers` - Get all registered workers

## Architecture

The orchestrator follows these steps:
1. **Queue**: Identifies services with empty `embedding_v2` values that aren't already being processed
2. **Claim**: Claims a batch of queued jobs
3. **Fetch**: Retrieves service data including taxonomies
4. **Tokenize**: Converts service descriptions and metadata into tokens
5. **Inference**: Sends tokens to inference workers to generate embeddings
6. **Store**: Saves embeddings back to the service table and marks jobs as completed

## Monitoring

The orchestrator provides statistics on:
- Jobs queued and processed
- Documents tokenized
- Embeddings generated
- Processing times for each stage
- Success rates

## Troubleshooting

### SQLx Compile-Time Errors
If you encounter SQLx compilation errors, you have two options:

1. Set the `DATABASE_URL` environment variable to enable online checking:
   ```
   export DATABASE_URL=postgres://postgres:password@localhost:5432/your_database
   ```

2. Generate SQLx prepare files:
   ```
   cargo install sqlx-cli
   cargo sqlx prepare
   ```

### Worker Connectivity
If workers aren't connecting, check:
- Network connectivity between orchestrator and workers
- Worker URLs in the `WORKER_LOCATIONS` environment variable
- API keys match between orchestrator and workers