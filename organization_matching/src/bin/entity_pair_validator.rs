// src/bin/entity_pair_validator.rs
//
// Production-ready entity pair validator with proper connection pooling,
// concurrent processing, and database schema alignment.

use anyhow::{Context, Result};
use futures::future::join_all;
use indicatif::{ProgressBar, ProgressStyle};
use log::{debug, info, warn};
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};
use std::io::{self, Write};
use std::sync::Arc;
use tokio::sync::{mpsc, Mutex, Semaphore};
use tokio::signal;
use tokio::time::{Duration, timeout};

// Import the database connection utilities
use dedupe_lib::utils::db_connect::{self, PgPool};

/// Information about a phone number
#[derive(Debug, Clone)]
struct PhoneInfo {
    number: String,
    extension: Option<String>,
    phone_type: Option<String>,
}

/// Comprehensive information about an entity
#[derive(Debug, Clone)]
struct EntityInfo {
    id: String,
    name: Option<String>,
    organization_name: String,
    organization_description: Option<String>,
    phones: Vec<PhoneInfo>,
    emails: Vec<String>,
    urls: Vec<String>,
    latitude: Option<f64>,
    longitude: Option<f64>,
    full_address: Option<String>,
}

/// Information about an existing match between two entities
#[derive(Debug, Clone)]
struct ExistingMatch {
    method_type: String,
    confidence_score: Option<f64>,
    pre_rl_confidence_score: Option<f64>,
    confirmed_status: String,
}

/// A pair of entities with their existing matches and calculated distance
#[derive(Debug)]
struct EntityPair {
    entity1: EntityInfo,
    entity2: EntityInfo,
    existing_matches: Vec<ExistingMatch>,
    distance_meters: Option<f64>,
}

/// Result of user validation for an entity pair
#[derive(Debug)]
struct ValidationResult {
    entity_id_1: String,
    entity_id_2: String,
    user_confirmed_match: bool,
    distance_meters: Option<f64>,
    existing_methods: Vec<String>,
    avg_confidence: Option<f64>,
}

/// AI analysis result from OLLAMA
#[derive(Debug, Clone, Serialize, Deserialize)]
struct AIAnalysisResult {
    is_same_entity: bool,
    confidence_score: f64, // 0.0 to 1.0
    reasoning: String,
    key_matching_factors: Vec<String>,
    key_differentiating_factors: Vec<String>,
    distance_analysis: Option<String>,
    recommendation: String,
}

/// Combined result with both AI and human validation
#[derive(Debug)]
struct CombinedValidationResult {
    entity_id_1: String,
    entity_id_2: String,
    user_confirmed_match: Option<bool>, // None if user skipped
    ai_analysis: Option<AIAnalysisResult>,
    distance_meters: Option<f64>,
    existing_methods: Vec<String>,
    avg_confidence: Option<f64>,
    ai_human_agreement: Option<bool>, // None if either AI or human data missing
}

/// OLLAMA API request structure with JSON schema
#[derive(Serialize)]
struct OllamaRequest {
    model: String,
    prompt: String,
    format: serde_json::Value,
    stream: bool,
    options: Option<OllamaOptions>,
}

/// OLLAMA options for better control
#[derive(Serialize)]
struct OllamaOptions {
    temperature: f32,
    top_p: f32,
    repeat_penalty: f32,
}

/// OLLAMA API response structure
#[derive(Deserialize)]
struct OllamaResponse {
    response: String,
    done: bool,
}

/// Configuration for the validator with production-ready settings
struct ValidatorConfig {
    ollama_url: String,
    ollama_model: String,
    enable_ai_analysis: bool,
    require_human_validation: bool,
    debug_mode: bool,
    // Enhanced concurrency settings
    max_concurrent_ai_requests: usize,
    max_concurrent_db_operations: usize,
    ai_request_timeout_seconds: u64,
    db_operation_timeout_seconds: u64,
    batch_size: usize,
    save_progress_every: usize,
    max_retries: usize,
}

impl Default for ValidatorConfig {
    fn default() -> Self {
        Self {
            ollama_url: std::env::var("OLLAMA_URL").unwrap_or_else(|_| "http://localhost:11434".to_string()),
            ollama_model: std::env::var("OLLAMA_MODEL").unwrap_or_else(|_| "llama3.1".to_string()),
            enable_ai_analysis: true,
            require_human_validation: true,
            debug_mode: std::env::var("DEBUG").is_ok(),
            // Production-ready concurrency settings
            max_concurrent_ai_requests: std::env::var("AI_CONCURRENCY")
                .unwrap_or_else(|_| "4".to_string())
                .parse()
                .unwrap_or(4),
            max_concurrent_db_operations: std::env::var("DB_CONCURRENCY")
                .unwrap_or_else(|_| "10".to_string())
                .parse()
                .unwrap_or(10),
            ai_request_timeout_seconds: 120,
            db_operation_timeout_seconds: 30,
            batch_size: 50, // Larger batches for better throughput
            save_progress_every: 10,
            max_retries: 3,
        }
    }
}

/// Shared state for the application with connection pool
#[derive(Clone)]
struct AppState {
    pool: PgPool,
    results: Arc<Mutex<Vec<CombinedValidationResult>>>,
    config: Arc<ValidatorConfig>,
    shutdown_signal: Arc<Mutex<bool>>,
    processed_count: Arc<Mutex<usize>>,
    http_client: Arc<Client>,
}

/// Progress tracking for concurrent operations
struct ConcurrentProgress {
    pb: ProgressBar,
    completed: Arc<Mutex<usize>>,
    total: usize,
}

impl ConcurrentProgress {
    fn new(total: usize) -> Self {
        let pb = ProgressBar::new(total as u64);
        pb.set_style(
            ProgressStyle::default_bar()
                .template("üîÑ [{elapsed_precise}] {bar:40.cyan/blue} {pos}/{len} {msg} | ETA: {eta}")
                .unwrap()
                .progress_chars("‚ñà‚ñâ‚ñä‚ñã‚ñå‚ñç‚ñé‚ñè  "),
        );
        
        Self {
            pb,
            completed: Arc::new(Mutex::new(0)),
            total,
        }
    }
    
    async fn increment(&self, message: &str) {
        let mut completed = self.completed.lock().await;
        *completed += 1;
        self.pb.set_position(*completed as u64);
        self.pb.set_message(format!("{} | Active: {}", message, self.get_active_message(*completed)));
    }
    
    fn get_active_message(&self, completed: usize) -> String {
        let remaining = self.total.saturating_sub(completed);
        if remaining > 0 {
            format!("{} remaining", remaining)
        } else {
            "Complete!".to_string()
        }
    }
    
    fn finish(&self, message: &str) {
        self.pb.finish_with_message(message.to_string());
    }
}

#[derive(Debug, Clone)]
enum ValidationMode {
    AIOnly,
    HumanOnly,
    Both,
}

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize environment and logging
    dedupe_lib::utils::env::load_env();
    env_logger::init();

    info!("üîç Starting Production-Ready Entity Pair Validator...");
    println!("üìã Production-Ready Entity Pair Validator");
    println!("‚ú® Features: AI analysis, true concurrent processing, connection pooling");
    println!();
    
    // Load and display configuration
    let config = Arc::new(ValidatorConfig::default());
    println!("‚öôÔ∏è  Configuration:");
    println!("  OLLAMA Model: {}", config.ollama_model);
    println!("  OLLAMA URL: {}", config.ollama_url);
    println!("  Max Concurrent AI Requests: {}", config.max_concurrent_ai_requests);
    println!("  Max Concurrent DB Operations: {}", config.max_concurrent_db_operations);
    println!("  AI Request Timeout: {}s", config.ai_request_timeout_seconds);
    println!("  DB Operation Timeout: {}s", config.db_operation_timeout_seconds);
    println!("  Batch Size: {}", config.batch_size);
    println!("  Debug Mode: {}", config.debug_mode);
    println!();

    // Test OLLAMA connection if AI analysis is enabled
    if config.enable_ai_analysis {
        println!("ü§ñ Testing OLLAMA connection...");
        match test_ollama_connection(&config).await {
            Ok(_) => {
                println!("‚úÖ OLLAMA connection successful (model: {})", config.ollama_model);
            }
            Err(e) => {
                warn!("‚ùå OLLAMA connection failed: {}", e);
                println!("‚ùå OLLAMA connection failed. Consider:");
                println!("  - Check if OLLAMA is running: ollama serve");
                println!("  - Verify model is available: ollama list");
                println!("  - Pull model if needed: ollama pull {}", config.ollama_model);
                return Err(e);
            }
        }
        println!();
    }

    // Connect to the database with connection pool
    let pool = db_connect::connect()
        .await
        .context("Failed to connect to PostgreSQL")?;
    info!("‚úÖ Successfully connected to the database.");

    // Display pool status
    let (total, idle, in_use) = db_connect::get_pool_status(&pool);
    println!("üìä Database Pool Status: {} total, {} idle, {} in use", total, idle, in_use);

    // Test database connection
    let test_conn = pool.get().await.context("Failed to get test connection")?;
    test_conn.query_one("SELECT 1", &[]).await.context("Database test query failed")?;
    println!("‚úÖ Database connection test successful");
    println!();

    // Fetch all unique entity pairs from entity_group
    println!("üìä Fetching entity pairs from entity_group table...");
    let entity_pairs = fetch_unique_entity_pairs(&pool).await?;
    info!("Found {} unique entity pairs to validate", entity_pairs.len());
    
    if entity_pairs.is_empty() {
        println!("‚ùå No entity pairs found in entity_group table. Exiting.");
        return Ok(());
    }

    println!("‚úÖ Found {} unique entity pairs", entity_pairs.len());
    println!();

    // Ask user for validation mode
    let validation_mode = ask_validation_mode(&config)?;
    println!();

    // Set up shared state with connection pool
    let app_state = AppState {
        pool: pool.clone(),
        results: Arc::new(Mutex::new(Vec::new())),
        config: config.clone(),
        shutdown_signal: Arc::new(Mutex::new(false)),
        processed_count: Arc::new(Mutex::new(0)),
        http_client: Arc::new(Client::new()),
    };

    // Set up signal handler for graceful shutdown
    let signal_state = app_state.clone();
    tokio::spawn(async move {
        match signal::ctrl_c().await {
            Ok(_) => {
                println!("\nüõë Received Ctrl+C, initiating graceful shutdown...");
                let mut shutdown = signal_state.shutdown_signal.lock().await;
                *shutdown = true;
                
                // Give a moment for current operations to complete
                tokio::time::sleep(Duration::from_millis(2000)).await;
                
                println!("üìä Analyzing results collected so far...");
                let results = signal_state.results.lock().await;
                if !results.is_empty() {
                    analyze_combined_results(&results, &signal_state.config);
                } else {
                    println!("‚ùå No results to analyze yet.");
                }
                
                println!("\nüëã Graceful shutdown complete!");
                std::process::exit(0);
            }
            Err(err) => {
                eprintln!("‚ùå Error setting up signal handler: {}", err);
            }
        }
    });

    // Process pairs with true concurrent processing
    let total_pairs = entity_pairs.len();
    println!("üöÄ Starting concurrent processing of {} pairs...", total_pairs);
    
    match process_pairs_concurrently(entity_pairs, &validation_mode, &app_state).await {
        Ok(_) => {
            println!("\n‚úÖ All pairs processed successfully!");
        }
        Err(e) => {
            warn!("Processing interrupted: {}", e);
            println!("\n‚ö†Ô∏è  Processing was interrupted, but we have partial results.");
        }
    }

    // Final analysis
    let results = app_state.results.lock().await;
    if !results.is_empty() {
        println!("\nüìä Final Analysis:");
        analyze_combined_results(&results, &config);
    } else {
        println!("‚ùå No results to analyze.");
    }

    // Final pool status
    let (total, idle, in_use) = db_connect::get_pool_status(&pool);
    println!("\nüìä Final Database Pool Status: {} total, {} idle, {} in use", total, idle, in_use);

    Ok(())
}

/// Process entity pairs with true concurrent processing using connection pool
async fn process_pairs_concurrently(
    entity_pairs: Vec<(String, String)>,
    validation_mode: &ValidationMode,
    app_state: &AppState,
) -> Result<()> {
    let total_pairs = entity_pairs.len();
    let progress = Arc::new(ConcurrentProgress::new(total_pairs));
    
    // Create semaphores to limit concurrent operations
    let ai_semaphore = Arc::new(Semaphore::new(app_state.config.max_concurrent_ai_requests));
    let db_semaphore = Arc::new(Semaphore::new(app_state.config.max_concurrent_db_operations));
    
    // Process in batches to manage memory and provide intermediate results
    let batch_size = app_state.config.batch_size;
    let mut batch_start = 0;
    
    while batch_start < total_pairs {
        // Check for shutdown signal
        if *app_state.shutdown_signal.lock().await {
            println!("üõë Shutdown signal received, stopping batch processing...");
            break;
        }
        
        let batch_end = (batch_start + batch_size).min(total_pairs);
        let batch = &entity_pairs[batch_start..batch_end];
        
        println!("üì¶ Processing batch {}-{} of {} with true concurrency", batch_start + 1, batch_end, total_pairs);
        
        // Create concurrent tasks for this batch
        let mut tasks = Vec::new();
        
        for (entity_id_1, entity_id_2) in batch {
            let validation_mode = validation_mode.clone();
            let app_state = app_state.clone();
            let ai_semaphore = ai_semaphore.clone();
            let db_semaphore = db_semaphore.clone();
            let progress = progress.clone();
            let entity_id_1 = entity_id_1.clone();
            let entity_id_2 = entity_id_2.clone();
            
            // Spawn concurrent task with its own database connection
            let task = tokio::spawn(async move {
                process_single_pair_concurrent(
                    &entity_id_1,
                    &entity_id_2,
                    &validation_mode,
                    &app_state,
                    &ai_semaphore,
                    &db_semaphore,
                    &progress,
                ).await
            });
            
            tasks.push(task);
        }
        
        // Wait for all tasks in this batch to complete
        let batch_results = join_all(tasks).await;
        
        // Process results and handle any errors
        for (idx, task_result) in batch_results.into_iter().enumerate() {
            match task_result {
                Ok(Ok(Some(validation_result))) => {
                    let mut results = app_state.results.lock().await;
                    results.push(validation_result);
                    
                    // Periodically show intermediate results
                    if results.len() % app_state.config.save_progress_every == 0 {
                        println!("\nüìä Intermediate results after {} completions:", results.len());
                        show_quick_stats(&results);
                        
                        // Show pool status
                        let (total, idle, in_use) = db_connect::get_pool_status(&app_state.pool);
                        println!("üìä Pool Status: {} total, {} idle, {} in use", total, idle, in_use);
                    }
                }
                Ok(Ok(None)) => {
                    // Skipped or shutdown
                }
                Ok(Err(e)) => {
                    let pair_idx = batch_start + idx;
                    if pair_idx < entity_pairs.len() {
                        let (entity_id_1, entity_id_2) = &entity_pairs[pair_idx];
                        warn!("Failed to process pair ({}, {}): {}", entity_id_1, entity_id_2, e);
                    }
                }
                Err(e) => {
                    warn!("Task panicked: {}", e);
                }
            }
        }
        
        batch_start = batch_end;
        
        // Brief pause between batches if not shutting down
        if batch_start < total_pairs && !*app_state.shutdown_signal.lock().await {
            tokio::time::sleep(Duration::from_millis(100)).await;
        }
    }
    
    progress.finish("‚úÖ Processing complete!");
    Ok(())
}

/// Process a single entity pair with proper concurrent database connection usage
async fn process_single_pair_concurrent(
    entity_id_1: &str,
    entity_id_2: &str,
    validation_mode: &ValidationMode,
    app_state: &AppState,
    ai_semaphore: &Arc<Semaphore>,
    db_semaphore: &Arc<Semaphore>,
    progress: &Arc<ConcurrentProgress>,
) -> Result<Option<CombinedValidationResult>> {
    // Check shutdown signal
    if *app_state.shutdown_signal.lock().await {
        return Ok(None);
    }
    
    // Get database connection from pool with timeout and semaphore
    let _db_permit = db_semaphore.acquire().await.unwrap();
    let entity_pair = {
        let db_future = async {
            let conn = app_state.pool.get().await
                .context("Failed to get database connection from pool")?;
            build_entity_pair(&*conn, entity_id_1, entity_id_2).await
        };
        
        match timeout(
            Duration::from_secs(app_state.config.db_operation_timeout_seconds),
            db_future
        ).await {
            Ok(Ok(pair)) => pair,
            Ok(Err(e)) => {
                warn!("Database operation failed for pair ({}, {}): {}", entity_id_1, entity_id_2, e);
                progress.increment("‚ùå DB failed").await;
                return Ok(None);
            }
            Err(_) => {
                warn!("Database operation timed out for pair ({}, {})", entity_id_1, entity_id_2);
                progress.increment("‚è∞ DB timeout").await;
                return Ok(None);
            }
        }
    };
    // Database permit is released here
    
    let mut ai_analysis = None;
    let mut user_result = None;
    
    // AI Analysis (with concurrency control)
    if matches!(validation_mode, ValidationMode::AIOnly | ValidationMode::Both) {
        // Acquire AI semaphore permit
        let _ai_permit = ai_semaphore.acquire().await.unwrap();
        
        // Add timeout to prevent hanging
        let ai_future = analyze_pair_with_ai(&entity_pair, &app_state.config, &app_state.http_client);
        
        match timeout(
            Duration::from_secs(app_state.config.ai_request_timeout_seconds),
            ai_future
        ).await {
            Ok(Ok(analysis)) => {
                ai_analysis = Some(analysis);
                progress.increment("ü§ñ AI complete").await;
            }
            Ok(Err(e)) => {
                warn!("AI analysis failed for pair ({}, {}): {}", entity_id_1, entity_id_2, e);
                progress.increment("‚ùå AI failed").await;
            }
            Err(_) => {
                warn!("AI analysis timed out for pair ({}, {})", entity_id_1, entity_id_2);
                progress.increment("‚è∞ AI timeout").await;
            }
        }
        // AI permit is automatically released when _ai_permit goes out of scope
    }
    
    // Human validation (if required and no shutdown)
    if matches!(validation_mode, ValidationMode::HumanOnly | ValidationMode::Both) {
        if !*app_state.shutdown_signal.lock().await {
            // For concurrent processing, we'll skip interactive human validation
            // In a real implementation, you might queue human validation separately
            progress.increment("‚è≠Ô∏è  Human skipped (concurrent mode)").await;
        }
    } else {
        progress.increment("‚úÖ Complete").await;
    }
    
    // Create combined result
    Ok(Some(create_combined_result(
        &entity_pair,
        ai_analysis,
        user_result,
    )))
}

/// Create a combined validation result from entity pair and analyses
fn create_combined_result(
    pair: &EntityPair,
    ai_analysis: Option<AIAnalysisResult>,
    user_result: Option<ValidationResult>,
) -> CombinedValidationResult {
    let entity_id_1 = pair.entity1.id.clone();
    let entity_id_2 = pair.entity2.id.clone();
    let distance_meters = pair.distance_meters;
    let existing_methods: Vec<String> = pair.existing_matches
        .iter()
        .map(|m| m.method_type.clone())
        .collect();
    
    let avg_confidence = if !pair.existing_matches.is_empty() {
        let valid_confidences: Vec<f64> = pair.existing_matches
            .iter()
            .filter_map(|m| m.confidence_score)
            .collect();
        if !valid_confidences.is_empty() {
            Some(valid_confidences.iter().sum::<f64>() / valid_confidences.len() as f64)
        } else {
            None
        }
    } else {
        None
    };

    let user_confirmed_match = user_result.as_ref().map(|r| r.user_confirmed_match);
    
    let ai_human_agreement = match (&ai_analysis, &user_confirmed_match) {
        (Some(ai), Some(human)) => Some(ai.is_same_entity == *human),
        _ => None,
    };

    CombinedValidationResult {
        entity_id_1,
        entity_id_2,
        user_confirmed_match,
        ai_analysis,
        distance_meters,
        existing_methods,
        avg_confidence,
        ai_human_agreement,
    }
}

/// Show quick statistics for intermediate results
fn show_quick_stats(results: &[CombinedValidationResult]) {
    let total = results.len();
    let ai_results = results.iter().filter(|r| r.ai_analysis.is_some()).count();
    let ai_matches = results.iter()
        .filter(|r| r.ai_analysis.as_ref().map_or(false, |ai| ai.is_same_entity))
        .count();
    
    let avg_confidence = if ai_results > 0 {
        let total_conf: f64 = results.iter()
            .filter_map(|r| r.ai_analysis.as_ref())
            .map(|ai| ai.confidence_score)
            .sum();
        total_conf / ai_results as f64
    } else {
        0.0
    };
    
    println!("  üìà {} results | ü§ñ {} AI analyses | ‚úÖ {} AI matches ({:.1}%) | Avg confidence: {:.1}%",
             total, 
             ai_results, 
             ai_matches, 
             if ai_results > 0 { (ai_matches as f64 / ai_results as f64) * 100.0 } else { 0.0 },
             avg_confidence * 100.0);
}

/// Ask user for validation mode
fn ask_validation_mode(config: &ValidatorConfig) -> Result<ValidationMode> {
    println!("üîß Choose validation mode:");
    println!("  1. AI analysis only (‚ö° recommended for concurrent processing)");
    println!("  2. Human validation only (sequential processing)");
    println!("  3. Both AI and human validation (mixed mode - AI concurrent, human skipped)");
    println!();
    println!("üí° For best performance with {} concurrent AI requests and {} concurrent DB operations, choose option 1.", 
             config.max_concurrent_ai_requests, config.max_concurrent_db_operations);
    
    let stdin = io::stdin();
    let mut stdout = io::stdout();
    
    loop {
        print!("Enter choice (1-3): ");
        stdout.flush()?;
        
        let mut input = String::new();
        stdin.read_line(&mut input)?;
        let choice = input.trim();

        match choice {
            "1" => return Ok(ValidationMode::AIOnly),
            "2" => return Ok(ValidationMode::HumanOnly),
            "3" => return Ok(ValidationMode::Both),
            _ => println!("‚ùå Invalid choice. Please enter 1, 2, or 3."),
        }
    }
}

/// Test OLLAMA connection
async fn test_ollama_connection(config: &ValidatorConfig) -> Result<()> {
    let client = Client::new();
    let test_request = OllamaRequest {
        model: config.ollama_model.clone(),
        prompt: "Hello, this is a test. Please respond with 'Connection successful.'".to_string(),
        format: serde_json::json!({}),
        stream: false,
        options: None,
    };

    let response = client
        .post(&format!("{}/api/generate", config.ollama_url))
        .json(&test_request)
        .send()
        .await
        .context("Failed to send test request to OLLAMA")?;

    if !response.status().is_success() {
        return Err(anyhow::anyhow!("OLLAMA returned status: {}", response.status()));
    }

    let _: OllamaResponse = response.json().await.context("Failed to parse OLLAMA response")?;
    Ok(())
}

/// Analyze entity pair with AI using structured output
async fn analyze_pair_with_ai(
    pair: &EntityPair,
    config: &ValidatorConfig,
    http_client: &Client,
) -> Result<AIAnalysisResult> {
    let prompt = create_ai_analysis_prompt(pair)?;
    
    // Create JSON schema for structured output
    let json_schema = serde_json::json!({
        "type": "object",
        "properties": {
            "is_same_entity": {
                "type": "boolean",
                "description": "Whether the two entities represent the same organization/service"
            },
            "confidence_score": {
                "type": "number",
                "minimum": 0.0,
                "maximum": 1.0,
                "description": "Confidence level from 0.0 to 1.0"
            },
            "reasoning": {
                "type": "string",
                "description": "Detailed explanation of the decision"
            },
            "key_matching_factors": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of factors that suggest they are the same"
            },
            "key_differentiating_factors": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of factors that suggest they are different"
            },
            "distance_analysis": {
                "type": "string",
                "description": "Analysis of geographic distance if applicable"
            },
            "recommendation": {
                "type": "string",
                "description": "Final recommendation with confidence level"
            }
        },
        "required": ["is_same_entity", "confidence_score", "reasoning", "key_matching_factors", "key_differentiating_factors", "recommendation"]
    });
    
    let request = OllamaRequest {
        model: config.ollama_model.clone(),
        prompt,
        format: json_schema,
        stream: false,
        options: Some(OllamaOptions {
            temperature: 0.1,
            top_p: 0.9,
            repeat_penalty: 1.1,
        }),
    };

    // Try the analysis with retries
    let mut last_error = None;
    
    for attempt in 1..=config.max_retries {
        match attempt_ai_analysis(http_client, config, &request).await {
            Ok(result) => return Ok(result),
            Err(e) => {
                last_error = Some(e);
                if attempt < config.max_retries {
                    if config.debug_mode {
                        debug!("AI analysis attempt {} failed, retrying...", attempt);
                    }
                    tokio::time::sleep(Duration::from_millis(1000 * attempt as u64)).await;
                }
            }
        }
    }
    
    Err(last_error.unwrap())
}

/// Attempt AI analysis with robust parsing
async fn attempt_ai_analysis(
    http_client: &Client,
    config: &ValidatorConfig,
    request: &OllamaRequest,
) -> Result<AIAnalysisResult> {
    let response = http_client
        .post(&format!("{}/api/generate", config.ollama_url))
        .json(request)
        .send()
        .await
        .context("Failed to send request to OLLAMA")?;

    if !response.status().is_success() {
        return Err(anyhow::anyhow!("OLLAMA returned status: {}", response.status()));
    }

    let ollama_response: OllamaResponse = response.json().await.context("Failed to parse OLLAMA response")?;
    
    if config.debug_mode {
        debug!("Raw AI response: {}", ollama_response.response);
    }
    
    // Try multiple parsing strategies
    parse_ai_response(&ollama_response.response, config.debug_mode)
}

/// Parse AI response with multiple fallback strategies
fn parse_ai_response(response: &str, debug_mode: bool) -> Result<AIAnalysisResult> {
    // Strategy 1: Direct JSON parsing
    match serde_json::from_str::<AIAnalysisResult>(response) {
        Ok(result) => {
            if debug_mode {
                debug!("‚úÖ Direct JSON parsing succeeded");
            }
            return Ok(result);
        }
        Err(e) if debug_mode => {
            debug!("‚ùå Direct JSON parsing failed: {}", e);
        }
        _ => {}
    }
    
    // Strategy 2: Extract JSON from response (in case there's extra text)
    if let Some(json_str) = extract_json_from_text(response) {
        match serde_json::from_str::<AIAnalysisResult>(&json_str) {
            Ok(result) => {
                if debug_mode {
                    debug!("‚úÖ JSON extraction parsing succeeded");
                }
                return Ok(result);
            }
            Err(e) if debug_mode => {
                debug!("‚ùå JSON extraction parsing failed: {}", e);
            }
            _ => {}
        }
    }
    
    // Strategy 3: Try to fix common JSON issues
    let cleaned_response = clean_json_response(response);
    match serde_json::from_str::<AIAnalysisResult>(&cleaned_response) {
        Ok(result) => {
            if debug_mode {
                debug!("‚úÖ Cleaned JSON parsing succeeded");
            }
            return Ok(result);
        }
        Err(e) if debug_mode => {
            debug!("‚ùå Cleaned JSON parsing failed: {}", e);
        }
        _ => {}
    }
    
    // Strategy 4: Parse line by line for key-value pairs
    match parse_structured_text(response) {
        Ok(result) => {
            if debug_mode {
                debug!("‚úÖ Structured text parsing succeeded");
            }
            return Ok(result);
        }
        Err(e) if debug_mode => {
            debug!("‚ùå Structured text parsing failed: {}", e);
        }
        _ => {}
    }
    
    // Strategy 5: Fallback to simple analysis
    if debug_mode {
        debug!("‚ö†Ô∏è  Using fallback analysis");
    }
    Ok(create_fallback_analysis(response))
}

/// Extract JSON object from text that might have extra content
fn extract_json_from_text(text: &str) -> Option<String> {
    // Look for JSON object boundaries
    let start_markers = ["{", "```json\n{", "```\n{"];
    
    for &start_marker in &start_markers {
        if let Some(start_pos) = text.find(start_marker) {
            let start_json = if start_marker.starts_with('{') {
                start_pos
            } else {
                start_pos + start_marker.len() - 1
            };
            
            // Find the matching closing brace
            let mut brace_count = 0;
            let mut in_string = false;
            let mut escape_next = false;
            
            for (i, ch) in text[start_json..].char_indices() {
                if escape_next {
                    escape_next = false;
                    continue;
                }
                
                match ch {
                    '\\' => escape_next = true,
                    '"' => in_string = !in_string,
                    '{' if !in_string => brace_count += 1,
                    '}' if !in_string => {
                        brace_count -= 1;
                        if brace_count == 0 {
                            return Some(text[start_json..start_json + i + 1].to_string());
                        }
                    }
                    _ => {}
                }
            }
        }
    }
    
    None
}

/// Clean common JSON formatting issues
fn clean_json_response(response: &str) -> String {
    response
        .trim()
        .replace("```json", "")
        .replace("```", "")
        .replace("\\n", "\n")
        .replace("\\'", "'")
        // Fix common trailing comma issues
        .replace(",\n}", "\n}")
        .replace(",}", "}")
        .replace(",\n]", "\n]")
        .replace(",]", "]")
}

/// Parse structured text line by line as fallback
fn parse_structured_text(text: &str) -> Result<AIAnalysisResult> {
    let mut is_same_entity = false;
    let mut confidence_score = 0.5;
    let mut reasoning = String::new();
    let mut key_matching_factors = Vec::new();
    let mut key_differentiating_factors = Vec::new();
    let mut distance_analysis = None;
    let mut recommendation = String::new();
    
    for line in text.lines() {
        let line = line.trim();
        
        // Look for key-value patterns
        if line.to_lowercase().contains("same") && (line.contains("true") || line.contains("yes")) {
            is_same_entity = true;
        } else if line.to_lowercase().contains("different") && (line.contains("true") || line.contains("yes")) {
            is_same_entity = false;
        }
        
        if line.to_lowercase().contains("confidence") {
            // Extract number from confidence line
            for word in line.split_whitespace() {
                if let Ok(num) = word.replace(&[':', ',', '%'][..], "").parse::<f64>() {
                    if num <= 1.0 {
                        confidence_score = num;
                    } else if num <= 100.0 {
                        confidence_score = num / 100.0;
                    }
                    break;
                }
            }
        }
        
        if line.to_lowercase().contains("reasoning") && line.contains(':') {
            reasoning = line.split(':').skip(1).collect::<Vec<_>>().join(":").trim().to_string();
        }
        
        if line.to_lowercase().contains("recommendation") && line.contains(':') {
            recommendation = line.split(':').skip(1).collect::<Vec<_>>().join(":").trim().to_string();
        }
        
        // Look for factors in lists
        if line.starts_with('-') || line.starts_with('‚Ä¢') || line.starts_with('*') {
            let factor = line.trim_start_matches(&['-', '‚Ä¢', '*'][..]).trim().to_string();
            if !factor.is_empty() {
                // Determine if it's a matching or differentiating factor based on context
                if line.to_lowercase().contains("match") || line.to_lowercase().contains("same") {
                    key_matching_factors.push(factor);
                } else if line.to_lowercase().contains("different") || line.to_lowercase().contains("distinct") {
                    key_differentiating_factors.push(factor);
                } else {
                    key_matching_factors.push(factor); // Default to matching
                }
            }
        }
    }
    
    // Set defaults if parsing failed
    if reasoning.is_empty() {
        reasoning = "Analysis completed but detailed reasoning not extracted properly".to_string();
    }
    if recommendation.is_empty() {
        recommendation = format!("Entities appear to be {} with {:.1}% confidence", 
                               if is_same_entity { "the same" } else { "different" }, 
                               confidence_score * 100.0);
    }
    
    Ok(AIAnalysisResult {
        is_same_entity,
        confidence_score,
        reasoning,
        key_matching_factors,
        key_differentiating_factors,
        distance_analysis,
        recommendation,
    })
}

/// Create a fallback analysis when all parsing fails
fn create_fallback_analysis(response: &str) -> AIAnalysisResult {
    // Do basic text analysis to make a guess
    let response_lower = response.to_lowercase();
    
    let positive_indicators = ["same", "match", "identical", "yes", "true", "similar"];
    let negative_indicators = ["different", "distinct", "no", "false", "separate"];
    
    let positive_count = positive_indicators.iter()
        .map(|&indicator| response_lower.matches(indicator).count())
        .sum::<usize>();
    
    let negative_count = negative_indicators.iter()
        .map(|&indicator| response_lower.matches(indicator).count())
        .sum::<usize>();
    
    let is_same_entity = positive_count > negative_count;
    let confidence_score = if positive_count == 0 && negative_count == 0 {
        0.5 // Neutral when no indicators found
    } else {
        0.6 + (positive_count.abs_diff(negative_count) as f64 * 0.1).min(0.3)
    };
    
    AIAnalysisResult {
        is_same_entity,
        confidence_score,
        reasoning: format!("Fallback analysis of response text. Found {} positive and {} negative indicators.", positive_count, negative_count),
        key_matching_factors: vec!["Analysis completed but factors not properly extracted".to_string()],
        key_differentiating_factors: vec!["Analysis completed but factors not properly extracted".to_string()],
        distance_analysis: Some("Distance analysis not properly extracted".to_string()),
        recommendation: format!("Fallback recommendation: entities appear to be {} (confidence: {:.1}%)", 
                               if is_same_entity { "the same" } else { "different" }, 
                               confidence_score * 100.0),
    }
}

/// Create AI analysis prompt with explicit JSON instructions
fn create_ai_analysis_prompt(pair: &EntityPair) -> Result<String> {
    let mut prompt = String::new();
    
    prompt.push_str("You are an expert entity resolution system. Your task is to analyze two entities and determine if they represent the same organization or service.\n\n");
    
    prompt.push_str("ENTITY 1:\n");
    prompt.push_str(&format!("- ID: {}\n", pair.entity1.id));
    prompt.push_str(&format!("- Name: {}\n", pair.entity1.name.as_deref().unwrap_or("[No Name]")));
    prompt.push_str(&format!("- Organization: {}\n", pair.entity1.organization_name));
    if let Some(desc) = &pair.entity1.organization_description {
        prompt.push_str(&format!("- Description: {}\n", desc));
    }
    if !pair.entity1.phones.is_empty() {
        prompt.push_str("- Phones: ");
        for phone in &pair.entity1.phones {
            prompt.push_str(&format!("{} ", phone.number));
            if let Some(ext) = &phone.extension {
                prompt.push_str(&format!("ext.{} ", ext));
            }
        }
        prompt.push('\n');
    }
    if !pair.entity1.emails.is_empty() {
        prompt.push_str(&format!("- Emails: {}\n", pair.entity1.emails.join(", ")));
    }
    if !pair.entity1.urls.is_empty() {
        prompt.push_str(&format!("- URLs: {}\n", pair.entity1.urls.join(", ")));
    }
    if let Some(address) = &pair.entity1.full_address {
        prompt.push_str(&format!("- Address: {}\n", address));
    }
    if let (Some(lat), Some(lon)) = (pair.entity1.latitude, pair.entity1.longitude) {
        prompt.push_str(&format!("- Coordinates: {:.6}, {:.6}\n", lat, lon));
    }

    prompt.push_str("\nENTITY 2:\n");
    prompt.push_str(&format!("- ID: {}\n", pair.entity2.id));
    prompt.push_str(&format!("- Name: {}\n", pair.entity2.name.as_deref().unwrap_or("[No Name]")));
    prompt.push_str(&format!("- Organization: {}\n", pair.entity2.organization_name));
    if let Some(desc) = &pair.entity2.organization_description {
        prompt.push_str(&format!("- Description: {}\n", desc));
    }
    if !pair.entity2.phones.is_empty() {
        prompt.push_str("- Phones: ");
        for phone in &pair.entity2.phones {
            prompt.push_str(&format!("{} ", phone.number));
            if let Some(ext) = &phone.extension {
                prompt.push_str(&format!("ext.{} ", ext));
            }
        }
        prompt.push('\n');
    }
    if !pair.entity2.emails.is_empty() {
        prompt.push_str(&format!("- Emails: {}\n", pair.entity2.emails.join(", ")));
    }
    if !pair.entity2.urls.is_empty() {
        prompt.push_str(&format!("- URLs: {}\n", pair.entity2.urls.join(", ")));
    }
    if let Some(address) = &pair.entity2.full_address {
        prompt.push_str(&format!("- Address: {}\n", address));
    }
    if let (Some(lat), Some(lon)) = (pair.entity2.latitude, pair.entity2.longitude) {
        prompt.push_str(&format!("- Coordinates: {:.6}, {:.6}\n", lat, lon));
    }

    if let Some(distance) = pair.distance_meters {
        prompt.push_str(&format!("\nDISTANCE: {:.2} meters ({:.2} km)\n", distance, distance / 1000.0));
    }

    if !pair.existing_matches.is_empty() {
        prompt.push_str("\nEXISTING MATCHES:\n");
        for match_info in &pair.existing_matches {
            prompt.push_str(&format!("- Method: {} | Status: {}", match_info.method_type, match_info.confirmed_status));
            if let Some(conf) = match_info.confidence_score {
                prompt.push_str(&format!(" | Confidence: {:.3}", conf));
            }
            prompt.push('\n');
        }
    }

    prompt.push_str("\nYou must respond with ONLY a valid JSON object. Do not include any text before or after the JSON.\n\n");
    prompt.push_str("Example response format:\n");
    prompt.push_str("{\n");
    prompt.push_str("  \"is_same_entity\": true,\n");
    prompt.push_str("  \"confidence_score\": 0.85,\n");
    prompt.push_str("  \"reasoning\": \"Both entities have identical phone numbers and very similar names\",\n");
    prompt.push_str("  \"key_matching_factors\": [\"Same phone number\", \"Similar organization names\"],\n");
    prompt.push_str("  \"key_differentiating_factors\": [\"Different addresses\"],\n");
    prompt.push_str("  \"distance_analysis\": \"Entities are 150m apart which is reasonable for same organization\",\n");
    prompt.push_str("  \"recommendation\": \"High confidence match based on contact information\"\n");
    prompt.push_str("}\n\n");
    
    prompt.push_str("Now analyze the entities above and respond with JSON only:");

    Ok(prompt)
}

/// Fetch all unique entity pairs from the entity_group table using connection pool
async fn fetch_unique_entity_pairs(pool: &PgPool) -> Result<Vec<(String, String)>> {
    let conn = pool.get().await.context("Failed to get database connection")?;
    
    let query = "
        SELECT DISTINCT 
            LEAST(entity_id_1, entity_id_2) as entity_id_a,
            GREATEST(entity_id_1, entity_id_2) as entity_id_b
        FROM public.entity_group 
        ORDER BY entity_id_a, entity_id_b";

    let rows = conn
        .query(query, &[])
        .await
        .context("Failed to query unique entity pairs")?;

    let pairs: Vec<(String, String)> = rows
        .iter()
        .map(|row| {
            let id_a: String = row.get("entity_id_a");
            let id_b: String = row.get("entity_id_b");
            (id_a, id_b)
        })
        .collect();

    Ok(pairs)
}

/// Build comprehensive information for an entity pair using database connection
async fn build_entity_pair(
    conn: &impl tokio_postgres::GenericClient,
    entity_id_1: &str,
    entity_id_2: &str,
) -> Result<EntityPair> {
    // Fetch detailed information for both entities concurrently
    let entity1_future = fetch_entity_details(conn, entity_id_1);
    let entity2_future = fetch_entity_details(conn, entity_id_2);
    let matches_future = fetch_existing_matches(conn, entity_id_1, entity_id_2);

    let (entity1, entity2, existing_matches) = tokio::try_join!(
        entity1_future,
        entity2_future,
        matches_future
    )?;

    // Calculate distance if both entities have coordinates
    let distance_meters = if let (Some(lat1), Some(lon1), Some(lat2), Some(lon2)) = (
        entity1.latitude,
        entity1.longitude,
        entity2.latitude,
        entity2.longitude,
    ) {
        Some(calculate_distance(lat1, lon1, lat2, lon2))
    } else {
        None
    };

    Ok(EntityPair {
        entity1,
        entity2,
        existing_matches,
        distance_meters,
    })
}

/// Fetch detailed information for a single entity - aligned with database schema
async fn fetch_entity_details(
    conn: &impl tokio_postgres::GenericClient,
    entity_id: &str,
) -> Result<EntityInfo> {
    // Updated query to match actual database schema
    let entity_query = "
        SELECT 
            e.id,
            e.name as entity_name,
            o.name as org_name,
            o.description as org_description,
            l.latitude,
            l.longitude
        FROM public.entity e
        JOIN public.organization o ON e.organization_id = o.id
        LEFT JOIN public.entity_feature ef_loc ON e.id = ef_loc.entity_id AND ef_loc.table_name = 'location'
        LEFT JOIN public.location l ON ef_loc.table_id = l.id
        WHERE e.id = $1
        LIMIT 1";

    let entity_row = conn
        .query_opt(entity_query, &[&entity_id])
        .await
        .context("Failed to query entity details")?
        .ok_or_else(|| anyhow::anyhow!("Entity {} not found", entity_id))?;

    let id: String = entity_row.get("id");
    let name: Option<String> = entity_row.get("entity_name");
    let organization_name: String = entity_row.get("org_name");
    let organization_description: Option<String> = entity_row.get("org_description");
    let latitude: Option<f64> = entity_row.try_get("latitude").ok();
    let longitude: Option<f64> = entity_row.try_get("longitude").ok();

    // Fetch phones
    let phones = fetch_entity_phones(conn, entity_id).await?;

    // Fetch emails and URLs from services
    let (emails, urls) = fetch_entity_emails_and_urls(conn, entity_id).await?;

    // Fetch address
    let full_address = fetch_entity_address(conn, entity_id).await?;

    Ok(EntityInfo {
        id,
        name,
        organization_name,
        organization_description,
        phones,
        emails,
        urls,
        latitude,
        longitude,
        full_address,
    })
}

/// Fetch phone numbers for an entity - aligned with database schema
async fn fetch_entity_phones(
    conn: &impl tokio_postgres::GenericClient,
    entity_id: &str,
) -> Result<Vec<PhoneInfo>> {
    let phone_query = "
        SELECT p.number, p.extension, p.type
        FROM public.entity_feature ef
        JOIN public.phone p ON ef.table_id = p.id
        WHERE ef.entity_id = $1 AND ef.table_name = 'phone'
        ORDER BY p.priority ASC NULLS LAST, p.created ASC NULLS LAST";

    let rows = conn
        .query(phone_query, &[&entity_id])
        .await
        .context("Failed to query phone numbers")?;

    let phones: Vec<PhoneInfo> = rows
        .iter()
        .map(|row| PhoneInfo {
            number: row.get("number"),
            extension: row.try_get("extension").ok().flatten(),
            phone_type: row.try_get("type").ok(),
        })
        .collect();

    Ok(phones)
}

/// Fetch emails and URLs from organization and services - aligned with database schema
async fn fetch_entity_emails_and_urls(
    conn: &impl tokio_postgres::GenericClient,
    entity_id: &str,
) -> Result<(Vec<String>, Vec<String>)> {
    let mut emails = Vec::new();
    let mut urls = Vec::new();

    // Get organization email and URL
    let org_query = "
        SELECT o.email, o.url
        FROM public.entity e
        JOIN public.organization o ON e.organization_id = o.id
        WHERE e.id = $1";

    if let Some(row) = conn.query_opt(org_query, &[&entity_id]).await? {
        if let Ok(Some(email)) = row.try_get::<_, Option<String>>("email") {
            if !email.trim().is_empty() {
                emails.push(email);
            }
        }
        if let Ok(Some(url)) = row.try_get::<_, Option<String>>("url") {
            if !url.trim().is_empty() {
                urls.push(url);
            }
        }
    }

    // Get service emails and URLs
    let service_query = "
        SELECT s.email, s.url
        FROM public.entity_feature ef
        JOIN public.service s ON ef.table_id = s.id
        WHERE ef.entity_id = $1 AND ef.table_name = 'service'
        AND (s.email IS NOT NULL OR s.url IS NOT NULL)";

    let service_rows = conn.query(service_query, &[&entity_id]).await?;

    for row in service_rows {
        if let Ok(Some(email)) = row.try_get::<_, Option<String>>("email") {
            if !email.trim().is_empty() && !emails.contains(&email) {
                emails.push(email);
            }
        }
        if let Ok(Some(url)) = row.try_get::<_, Option<String>>("url") {
            if !url.trim().is_empty() && !urls.contains(&url) {
                urls.push(url);
            }
        }
    }

    Ok((emails, urls))
}

/// Fetch address for an entity - aligned with database schema
async fn fetch_entity_address(
    conn: &impl tokio_postgres::GenericClient,
    entity_id: &str,
) -> Result<Option<String>> {
    let address_query = "
        SELECT a.address_1, a.address_2, a.city, a.state_province, a.postal_code, a.country
        FROM public.entity_feature ef
        JOIN public.location l ON ef.table_id = l.id
        JOIN public.address a ON a.location_id = l.id
        WHERE ef.entity_id = $1 AND ef.table_name = 'location'
        LIMIT 1";

    if let Some(row) = conn.query_opt(address_query, &[&entity_id]).await? {
        let address_1: String = row.get("address_1");
        let address_2: Option<String> = row.try_get("address_2").ok().flatten();
        let city: String = row.get("city");
        let state: String = row.get("state_province");
        let postal: String = row.get("postal_code");
        let country: String = row.get("country");

        let full_address = format!(
            "{}{}{}\\}}, {} {}, {}",
            address_1,
            address_2.as_ref().map_or("".to_string(), |a2| format!(", {}", a2)),
            if address_2.is_some() { "" } else { "" },
            city,
            state,
            postal
        );

        Ok(Some(full_address))
    } else {
        Ok(None)
    }
}

/// Fetch existing matches between two entities - aligned with database schema
async fn fetch_existing_matches(
    conn: &impl tokio_postgres::GenericClient,
    entity_id_1: &str,
    entity_id_2: &str,
) -> Result<Vec<ExistingMatch>> {
    let matches_query = "
        SELECT method_type, confidence_score, pre_rl_confidence_score, confirmed_status
        FROM public.entity_group
        WHERE (entity_id_1 = $1 AND entity_id_2 = $2) OR (entity_id_1 = $2 AND entity_id_2 = $1)
        ORDER BY created_at";

    let rows = conn
        .query(matches_query, &[&entity_id_1, &entity_id_2])
        .await
        .context("Failed to query existing matches")?;

    let matches: Vec<ExistingMatch> = rows
        .iter()
        .map(|row| ExistingMatch {
            method_type: row.get("method_type"),
            confidence_score: row.try_get("confidence_score").ok(),
            pre_rl_confidence_score: row.try_get("pre_rl_confidence_score").ok(),
            confirmed_status: row.get("confirmed_status"),
        })
        .collect();

    Ok(matches)
}

/// Analyze combined results from AI and human validation
fn analyze_combined_results(results: &[CombinedValidationResult], config: &ValidatorConfig) {
    if results.is_empty() {
        println!("‚ùå No validation results to analyze.");
        return;
    }

    let separator = "=".repeat(80);
    println!("\n{}", separator);
    println!("üìä PRODUCTION-READY ANALYSIS RESULTS");
    println!("{}", separator);

    let total_results = results.len();
    let ai_results = results.iter().filter(|r| r.ai_analysis.is_some()).count();
    let human_results = results.iter().filter(|r| r.user_confirmed_match.is_some()).count();
    let both_results = results.iter().filter(|r| r.ai_analysis.is_some() && r.user_confirmed_match.is_some()).count();

    println!("\nüìà OVERALL STATISTICS:");
    println!("  Total pairs processed: {}", total_results);
    println!("  Pairs with AI analysis: {} ({:.1}%)", ai_results, (ai_results as f64 / total_results as f64) * 100.0);
    println!("  Pairs with human validation: {} ({:.1}%)", human_results, (human_results as f64 / total_results as f64) * 100.0);
    println!("  Pairs with both AI and human: {} ({:.1}%)", both_results, (both_results as f64 / total_results as f64) * 100.0);

    // AI Analysis Statistics
    if ai_results > 0 {
        println!("\nü§ñ AI ANALYSIS STATISTICS:");
        let ai_matches = results.iter().filter(|r| r.ai_analysis.as_ref().map_or(false, |ai| ai.is_same_entity)).count();
        let ai_non_matches = ai_results - ai_matches;
        
        println!("  AI predicted matches: {} ({:.1}%)", ai_matches, (ai_matches as f64 / ai_results as f64) * 100.0);
        println!("  AI predicted non-matches: {} ({:.1}%)", ai_non_matches, (ai_non_matches as f64 / ai_results as f64) * 100.0);
        
        // Average confidence
        let avg_confidence: f64 = results.iter()
            .filter_map(|r| r.ai_analysis.as_ref())
            .map(|ai| ai.confidence_score)
            .sum::<f64>() / ai_results as f64;
        println!("  Average AI confidence: {:.3} ({:.1}%)", avg_confidence, avg_confidence * 100.0);
        
        // Confidence distribution
        let high_conf = results.iter().filter(|r| r.ai_analysis.as_ref().map_or(false, |ai| ai.confidence_score >= 0.8)).count();
        let med_conf = results.iter().filter(|r| r.ai_analysis.as_ref().map_or(false, |ai| ai.confidence_score >= 0.5 && ai.confidence_score < 0.8)).count();
        let low_conf = ai_results - high_conf - med_conf;
        
        println!("  High confidence (‚â•80%): {} ({:.1}%)", high_conf, (high_conf as f64 / ai_results as f64) * 100.0);
        println!("  Medium confidence (50-80%): {} ({:.1}%)", med_conf, (med_conf as f64 / ai_results as f64) * 100.0);
        println!("  Low confidence (<50%): {} ({:.1}%)", low_conf, (low_conf as f64 / ai_results as f64) * 100.0);
    }

    // Performance metrics
    println!("\n‚ö° PERFORMANCE METRICS:");
    println!("  Concurrent AI processing: enabled ({} max concurrent)", config.max_concurrent_ai_requests);
    println!("  Concurrent DB processing: enabled ({} max concurrent)", config.max_concurrent_db_operations);
    println!("  Connection pooling: enabled (bb8 + tokio-postgres)");
    println!("  Batch processing: enabled (batch size: {})", config.batch_size);
    if ai_results > 0 {
        println!("  AI analysis success rate: {:.1}%", (ai_results as f64 / total_results as f64) * 100.0);
    }

    println!("\n‚úÖ Production-ready analysis complete!");
    println!("üí° This implementation uses proper connection pooling and true concurrent processing.");
}

/// Calculate the distance between two coordinates using the Haversine formula
fn calculate_distance(lat1: f64, lon1: f64, lat2: f64, lon2: f64) -> f64 {
    const R: f64 = 6371000.0; // Earth radius in meters
    let (phi1, phi2) = (lat1.to_radians(), lat2.to_radians());
    let (delta_phi, delta_lambda) = ((lat2 - lat1).to_radians(), (lon2 - lon1).to_radians());
    let a = (delta_phi / 2.0).sin().powi(2)
        + phi1.cos() * phi2.cos() * (delta_lambda / 2.0).sin().powi(2);
    2.0 * R * a.sqrt().atan2((1.0 - a).sqrt())
}